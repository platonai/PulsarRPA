<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl" ?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <property>
        <name>pulsar.config.id</name>
        <value>test</value>
    </property>

    <!-- persist -->
    <property>
        <name>storage.crawl.id</name>
        <value>pulsar_tmp</value>
        <description>Crawl amazon web pages</description>
    </property>

    <!-- crawl -->
    <property>
        <name>crawl.max.distance</name>
        <value>2</value>
    </property>

    <!-- fetch -->
    <property>
        <name>fetch.concurrency</name>
        <value>5</value>
    </property>

    <property>
        <name>fetch.threads.per.pool</name>
        <value>-1</value>
        <description>This number is the maximum number of threads that
            should be allowed to access a queue at one time. Setting it to
            a value > 1 will cause the Crawl-Delay value from robots.txt to
            be ignored and the value of fetch.queue.min.delay to be used
            as a delay between successive requests to the same server instead
            of fetch.queue.delay.
        </description>
    </property>

    <property>
        <name>parse.min.anchor.length</name>
        <!--<value>8</value>-->
        <value>2</value>
    </property>
    <property>
        <name>parse.max.anchor.length</name>
        <value>200</value>
    </property>

    <property>
        <name>mapreduce.job.reduces</name>
        <value>2</value>
    </property>

</configuration>
