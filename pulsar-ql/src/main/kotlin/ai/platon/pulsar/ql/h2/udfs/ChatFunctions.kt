package ai.platon.pulsar.ql.h2.udfs

import ai.platon.pulsar.ql.common.annotation.UDFGroup
import ai.platon.pulsar.ql.common.annotation.UDFunction
import ai.platon.pulsar.ql.common.types.ValueDom
import ai.platon.pulsar.ql.context.SQLContexts

/**
 * Chat and conversational AI functions for X-SQL queries in Pulsar QL.
 *
 * This object provides conversational AI capabilities within X-SQL queries,
 * enabling natural language interactions and AI-powered responses directly
 * from SQL queries.
 *
 * ## Function Categories
 *
 * ### Conversational AI
 * - [chat] - Send messages to AI model with system context
 *
 * ## Usage Examples
 *
 * ```sql
 * -- Simple chat with AI
 * SELECT DOM.chat('Hello, how are you?', 'You are a helpful assistant');
 *
 * -- Chat with custom system message
 * SELECT DOM.chat(
 *   'Extract the main topic from this text',
 *   'You are a text analysis expert. Provide concise answers.'
 * );
 *
 * -- Combine with other functions
 * SELECT DOM.chat(
 *   CONCAT('Summarize this content: ', DOM.text(DOM.load('https://example.com'))),
 *   'You are a content summarizer. Provide a brief summary.'
 * );
 * ```
 *
 * ## X-SQL Integration
 *
 * Chat functions are automatically registered as H2 database functions under the
 * "DOM" namespace. They can be used directly in X-SQL queries and combined with
 * other DOM functions for AI-powered content processing.
 *
 * ## AI Response Format
 *
 * The AI model returns natural language responses based on the input message and
 * system context. Responses are suitable for direct use in queries or further processing.
 *
 * ## Performance Notes
 *
 * - Chat operations may have higher latency than traditional functions
 * - Results are generated by AI models in real-time
 * - Response quality depends on input prompt and system context
 * - Rate limiting may apply based on AI service configuration
 *
 * ## Thread Safety
 *
 * All functions in this object are thread-safe and can be safely used
 * in concurrent query execution contexts.
 *
 * @author Pulsar AI
 * @since 1.0.0
 * @see SQLContexts
 * @see UDFGroup
 * @see UDFunction
 */
@Suppress("unused")
@UDFGroup(namespace = "DOM")
object ChatFunctions {

    private val sqlContext get() = SQLContexts.create()
    private val unmodifiedConfig get() = sqlContext.unmodifiedConfig

    /**
     * Sends a chat message to the AI model with system context and returns the response.
     *
     * This function enables conversational AI interactions within X-SQL queries by sending
     * a user message along with system context to the configured AI model and returning
     * the generated response.
     *
     * ## X-SQL Usage
     * ```sql
     * -- Simple conversation
     * SELECT DOM.chat('Hello!', 'You are a helpful assistant'); -- returns AI response
     *
     * -- Content analysis with AI
     * SELECT DOM.chat(
     *   'What is the main topic of machine learning?',
     *   'You are a technology expert. Provide concise explanations.'
     * );
     *
     * -- Dynamic content processing
     * SELECT DOM.chat(
     *   CONCAT('Summarize this: ', DOM.text(DOM.selectFirst(dom, 'article'))),
     *   'You are a content summarizer. Provide 2-3 sentence summaries.'
     * ) FROM (SELECT DOM.load('https://example.com') as dom) t;
     * ```
     *
     * ## Use Cases
     * - Natural language processing within queries
     * - Content analysis and summarization
     * - Question answering from extracted data
     * - AI-powered data transformation
     * - Conversational data extraction
     *
     * ## Message Parameters
     * - **userMessage**: The main question or request to the AI model
     * - **systemMessage**: Context or instructions for the AI model's behavior
     *
     * ## Response Format
     * Returns the AI model's response as a string. The response format depends on:
     * - The input user message
     * - The system context provided
     * - The configured AI model capabilities
     *
     * ## Performance Considerations
     * - AI model calls may have higher latency than traditional functions
     * - Response time depends on model complexity and input length
     * - Results are generated in real-time by the AI service
     * - Consider caching for repeated similar queries
     *
     * ## Configuration Dependencies
     * - Uses the session's configured AI model and settings
     * - Respects rate limiting and timeout configurations
     * - Requires active AI service integration
     *
     * @param userMessage The user's message or question to the AI model
     * @param systemMessage System context or instructions for the AI model
     * @return The AI model's response content as a string
     * @see SQLContexts.chat
     * @see unmodifiedConfig for AI model configuration
     */
    @UDFunction(description = "Chat with the AI model")
    @JvmStatic
    fun chat(userMessage: String, systemMessage: String): String {
        return sqlContext.chat(userMessage, systemMessage).content
    }
}
